{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP : 스파트 사용환경 구축 \n",
    "\n",
    "*- Pyspark Install*\n",
    "- 혹시 Visual C++ 런타임 라이브러리여부를 확인하고 없다면 설치하는 것이 좋다.\n",
    "    - 설치: <https://knowledge.autodesk.com/ko/search-result/caas/sfdcarticles/sfdcarticles/KOR/How-to-remove-and-reinstall-Microsoft-Visual-C-Runtime-Libraries.html>   \n",
    "  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 자바 설치 \n",
    "\n",
    "커맨드(cmd)창에 다음과 같이 입력했을때 출력이 있어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```cmd\n",
    "$ java -version\n",
    "\n",
    ">>> java version \"1.8.0_144\"\n",
    "    Java(TM) SE Runtime Environment (build 1.8.0_144-b01)\n",
    "    Java HotSpot(TM) Client VM (build 25.144-b01, mixed mode, sharing)\n",
    "\n",
    "```\n",
    "\n",
    "만약 위와 같이 나오지 않는다면 자바가 설치가 안 된 것이므로 아래 링크에서 설치한다.\n",
    "\n",
    "설치경로 1 : < https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html >\n",
    "설치경로 2 : < https://www.apache.org/dyn/closer.lua/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz >\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 자바 환경변수 설정 \n",
    "\n",
    "시스템 환경변수에서 아래와같이 설정 해주어야한다.\n",
    "\n",
    "```bash\n",
    "\n",
    "# JAVA_HOME 변수를 설정\n",
    "JAVA_HOME = C:\\Program Files\\Java\\jdk1.8.0_201\n",
    "\n",
    "# 경로를 환경변수에 추가 \n",
    "C:\\Program Files\\Java\\jdk1.8.0_201\\bin        \n",
    "\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 자바 환경변수 설정 확인\n",
    "\n",
    "- CMD 창 재시작 후 \n",
    "    - `$where yarn`\n",
    "- Winutils 확인 \n",
    "    - `$ where winutils.exe`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SPARK Install\n",
    "스파크 설치를 진행하기위해 아래의 링크에서 데이터를 다운받는다. \n",
    "\n",
    "설치 경로 : <http://spark.apache.org/downloads.html>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 스파크 환경변수 설정 \n",
    "\n",
    "시스템 환경변수에서 아래와 같이 설정이 필요하다.\n",
    "\n",
    "추가 )     \n",
    "복붙시 파일이름은 본인들 파일이름 일 것      \n",
    "본인들이 다운받은 파일과 동일한 파일 이름일 것 - 아래는 예시 \n",
    "\n",
    "```bash\n",
    "\n",
    "# SPARK_HOME, HADOOP_HOME변수를 설정\n",
    "SPARK_HOME = C:\\spark\\spark-2.3.2-bin-hadoop2.7\n",
    "HADOOP_HOME = C:\\spark\\hadoop2.7 \n",
    "\n",
    "# PATH에 아래와 같이 선언 \n",
    "C:\\spark\\spark-2.3.2-bin-hadoop2.7\\bin        \n",
    "\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. winutils.exe 설치\n",
    "\n",
    "설치 경로: <https://github.com/steveloughran/winutils> \n",
    "\n",
    "하둡버전과 동일하게 설치를 진행해준다.      \n",
    "다운받은 winutils.exe를 스파크를 설치해준 bin폴더에 저장한다.      \n",
    "\n",
    "예) 현재 내경로 ->  C:\\spark\\spark-2.3.2-bin-hadoop2.7\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 폴더생성 \n",
    "\n",
    "`C:\\tmp\\hive` 와 동일한 경로에 폴더를 생성한다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 관리자 권한으로 cmd를 실행시키고 두개의 명령어를 실행\n",
    "\n",
    "\n",
    "```bash\n",
    "\n",
    "$ winutils.exe chmod -R 777 C:\\tmp\\hive\n",
    "$ winutils.exe ls -F C:\\tmp\\hive\n",
    "```\n",
    "\n",
    "이렇게 실행하면 다음과 유사하게 출력됨\n",
    "\n",
    "```bash\n",
    ">>> drwxrwxrwx|1|LAPTOP-.....\n",
    "\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Pyspark 설치 확인 \n",
    "\n",
    "`conda install -c conda-forge pyspark`\n",
    "\n",
    "cmd창에 들어가서 pyspark명령어를 치면 \n",
    "아래와 같이 뜨면 성공 \n",
    "\n",
    "```cmd\n",
    "\n",
    "(base) C:\\>pyspark\n",
    "Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)] on win32\n",
    "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
    "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
    "Setting default log level to \"WARN\".\n",
    "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
    "Welcome to\n",
    "      ____              __\n",
    "     / __/__  ___ _____/ /__\n",
    "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
    "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.5\n",
    "      /_/\n",
    "\n",
    "\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Pyspark 설치 확인 - 체크 \n",
    "\n",
    "추가 확인으로 pyspark 실행후 다음과 같은 명령어가 동작하는지 확인 \n",
    "\n",
    "```cmd\n",
    "\n",
    "nums = sc.parallelize([1,2,3,4])\n",
    "nums.map(lambda x:x*x).collect()\n",
    "\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pyspark를 쥬피터 노트북에 연결 \n",
    "\n",
    "anaconda prompt가 설치되어있다는 가정하에 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "아래의 명령어를 실행한다. \n",
    "\n",
    "```cmd\n",
    "# findspark 설치 \n",
    "$ conda install -c conda-forge findspark\n",
    "```\n",
    "이후 jupyter notebook을 실행시키고 다음과 같이 컴파일\n",
    "\n",
    "```py\n",
    "import findspark \n",
    "findspark.init()\n",
    "findspark.find() \n",
    "\n",
    "import pyspark \n",
    "findspark.find()\n",
    "\n",
    "# spark 세션을 생성해주기위해서 다음과 같이 컴파일을 진행해준다.\n",
    "\n",
    "from pyspark import SparkContext, SparkConf \n",
    "from pyspark.sql import SparkSession \n",
    "\n",
    "conf = pyspark.SparkConf().setAppName('appName').setMaster('local’) \n",
    "sc = pyspark.SparkContext(conf=conf) # sc에 스파크 콘텍스트를 담는다.\n",
    "spark = SparkSession(sc) # sc를 세션을 할당한다.\n",
    "\n",
    "# 만약 세션이 끝난다면 다음과같은 코드를 실행한다\n",
    "sc.stop() # 세션 종료\n",
    "```\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
